{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Embeddings and Convert to DataFrame\n",
    "\n",
    "Also combine any additional embeddings generated from custom pdb requests\n",
    "\n",
    "<div>UPDATE (as of 5 AM Friday -> Saturday): </div> This notebook is now obsolete on account of an inability to process all the sliced datums. The full CHROMA dataset is too large to be properly handled right now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Run once cell (because of location of notebook, i.e. not in base directory)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# Add the parent directory to the path so we can import the modules\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "from helpers.database import populate_representations, get_column, get_scalars, whatis\n",
    "from helpers.edges import connect_edges, CascadingEdges\n",
    "from helpers.cascades import Cascade, MakeCascade, Metrics, MetricsPair, MakeMetricsPair\n",
    "from helpers.load_data import LoadData, save_df, save_edges\n",
    "\n",
    "\n",
    "from functools import partial\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import jax.numpy as jnp\n",
    "from jax import vmap, lax\n",
    "\n",
    "from moleculib.assembly.dataset import ChromaDataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading reduced data\n",
      "--- 8.693283796310425 seconds ---\n",
      "Loading full data\n"
     ]
    },
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 53\u001b[0m\n\u001b[1;32m     51\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading full data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 53\u001b[0m \u001b[43mchroma_full\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--- \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m seconds ---\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time))\n",
      "Cell \u001b[0;32mIn[19], line 34\u001b[0m, in \u001b[0;36mLoadData.load_all\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_all\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_embeddings()\n\u001b[0;32m---> 34\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_sliced_proteins\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtsne_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     36\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_tsne()\n",
      "Cell \u001b[0;32mIn[19], line 26\u001b[0m, in \u001b[0;36mLoadData.load_sliced_proteins\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_sliced_proteins\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mFOLDER\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msliced_proteins_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 26\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msliced_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "# FOLDER_PREAMBLE = \"../scripts/\"\n",
    "FOLDER_PREAMBLE = \"../data\"\n",
    "\n",
    "\n",
    "REDUCED_FOLDER = FOLDER_PREAMBLE + \"/\" + \"denim-energy-1008-embeddings\"\n",
    "FULL_FOLDER = FOLDER_PREAMBLE + \"/\" + \"denim-energy-full-CHROMA\"\n",
    "\n",
    "# General file path names\n",
    "embeddings_file = \"encoded_dataset.pkl\"\n",
    "sliced_proteins_file = \"sliced_dataset.pkl\"\n",
    "tsne_file = \"encoded_dataset_tsne.json\"\n",
    "\n",
    "\n",
    "chroma_reduced = LoadData(REDUCED_FOLDER, embeddings_file, sliced_proteins_file, tsne_file)\n",
    "chroma_full = LoadData(FULL_FOLDER, embeddings_file, sliced_proteins_file)\n",
    "\n",
    "start_time = time.time()\n",
    "print(\"Loading reduced data\")\n",
    "chroma_reduced.load_all()\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "start_time = time.time()\n",
    "print(\"Loading full data\")\n",
    "chroma_full.load_all()\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mload(file)\n\u001b[0;32m----> 8\u001b[0m test_sliced \u001b[38;5;241m=\u001b[39m \u001b[43mload_sliced_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../../../ophiuchus/scripts/saved_embeddings/denim-energy-full-CHROMA/sliced_dataset.pkl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSliced datasets loaded successfully.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m, in \u001b[0;36mload_sliced_dataset\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_sliced_dataset\u001b[39m(file_path):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m----> 6\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Function to load the sliced dataset\n",
    "def load_sliced_dataset(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        return pickle.load(file)\n",
    "        \n",
    "test_sliced = load_sliced_dataset(\"../../../ophiuchus/scripts/saved_embeddings/denim-energy-full-CHROMA/sliced_dataset.pkl\")\n",
    "\n",
    "print(\"Sliced datasets loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_sliced' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtest_sliced\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_sliced' is not defined"
     ]
    }
   ],
   "source": [
    "test_sliced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chroma Reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded full dataset: (431465, 7)\n",
      "Number of nodes per level:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "level\n",
       "0    221142\n",
       "1    111222\n",
       "2     56215\n",
       "3     28602\n",
       "4     14284\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of None datums: 5375\n"
     ]
    }
   ],
   "source": [
    "# Make objects\n",
    "reps_reduced, _ = populate_representations(chroma_reduced.encoded_dataset, chroma_reduced.sliced_dataset, chroma_reduced.tsne_data)\n",
    "df_reduced = reps_reduced.to_dataframe()\n",
    "print(f\"Loaded full dataset: {df_reduced.shape}\")\n",
    "\n",
    "# Calculate the number of nodes per level\n",
    "nodes_per_level_reduced = df_reduced.groupby('level').size()\n",
    "print(\"Number of nodes per level:\")\n",
    "display(nodes_per_level_reduced)\n",
    "\n",
    "# Count the \"None\" datums\n",
    "n_none_datums_reduced = df_reduced[df_reduced['datum'].isnull()].shape[0]\n",
    "print(f\"Number of None datums: {n_none_datums_reduced}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chroma Full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded full dataset: (431465, 7)\n",
      "Number of nodes per level:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "level\n",
       "0    221142\n",
       "1    111222\n",
       "2     56215\n",
       "3     28602\n",
       "4     14284\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of None datums: 5375\n",
      "CPU times: user 1.94 s, sys: 61.5 ms, total: 2 s\n",
      "Wall time: 2.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Make objects\n",
    "reps_full, _ = populate_representations(chroma_full.encoded_dataset, chroma_full.sliced_dataset)\n",
    "df_full = reps_full.to_dataframe()\n",
    "print(f\"Loaded full dataset: {df_full.shape}\")\n",
    "\n",
    "# Calculate the number of nodes per level\n",
    "nodes_per_level_full = df_full.groupby('level').size()\n",
    "print(\"Number of nodes per level:\")\n",
    "display(nodes_per_level_full)\n",
    "\n",
    "# Count the \"None\" datums\n",
    "n_none_datums_full = df_full[df_full['datum'].isnull()].shape[0]\n",
    "print(f\"Number of None datums: {n_none_datums_full}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
