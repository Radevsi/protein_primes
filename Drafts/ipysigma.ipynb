{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "277014ad-efd7-42ef-861c-2f15b144b241",
   "metadata": {},
   "source": [
    "# Visualization with full distance scores and metrics\n",
    "\n",
    "We will jump straight to visualizing via TSNE and PySigma, after calculating edges.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfca3526",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680df1fb-b4a1-47c6-b9b8-7ecf00033769",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Standard library\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Third-party\n",
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from ipysigma import Sigma\n",
    "\n",
    "from helpers_new import populate_representations, get_column, get_scalars, whatis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968813dd",
   "metadata": {},
   "source": [
    "#### Load embeddings and sliced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e1aa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_PREAMBLE = \"../scripts/\"\n",
    "FOLDER = FOLDER_PREAMBLE + \"denim-energy-1008-embeddings\"\n",
    "FOLDER_SMALL_FILES = FOLDER_PREAMBLE + \"test-save\"\n",
    "embeddings_file = \"encoded_dataset.pkl\"\n",
    "sliced_proteins_file = \"sliced_dataset.pkl\"\n",
    "\n",
    "# Open both and store\n",
    "with open(f\"{FOLDER}/{embeddings_file}\", \"rb\") as f:\n",
    "    encoded_dataset = pickle.load(f)\n",
    "with open(f\"{FOLDER}/{sliced_proteins_file}\", \"rb\") as f:\n",
    "    sliced_dataset = pickle.load(f)\n",
    "\n",
    "# Load the small folder's files\n",
    "with open(f\"{FOLDER_SMALL_FILES}/{embeddings_file}\", \"rb\") as f:\n",
    "    encoded_dataset_small = pickle.load(f)\n",
    "with open(f\"{FOLDER_SMALL_FILES}/{sliced_proteins_file}\", \"rb\") as f:\n",
    "    sliced_dataset_small = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5218f6",
   "metadata": {},
   "source": [
    "#### Load TSNE files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37265d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_file = \"encoded_dataset_tsne.json\"\n",
    "\n",
    "# Load the tsne file\n",
    "with open(f\"{FOLDER}/{tsne_file}\", \"r\") as f:\n",
    "    tsne_data = json.load(f)\n",
    "\n",
    "# Load the small tsne file\n",
    "with open(f\"{FOLDER_SMALL_FILES}/{tsne_file}\", \"r\") as f:\n",
    "    tsne_data_small = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6caa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the small dataset into the database\n",
    "reps_db_small, mismatches = populate_representations(encoded_dataset_small, sliced_dataset_small, tsne_data_small)\n",
    "df_small = reps_db_small.to_dataframe()\n",
    "print(df_small.shape)\n",
    "df_small.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dc73ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all unique levels\n",
    "unique_levels = df_small[\"level\"].unique()\n",
    "unique_levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f5f98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for nones\n",
    "print(df_small.isnull().sum())\n",
    "\n",
    "# Get a distribution of the pdb ids where datum is none\n",
    "print(df_small[df_small[\"datum\"].isnull()][\"pdb_id\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f01a4f",
   "metadata": {},
   "source": [
    "### Connect Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cdd165",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kernel_size, stride = 5, 2\n",
    "def connect_edges(df, kernel_size, stride):\n",
    "\n",
    "    n_misses = 0\n",
    "    edges_top_down, edges_bottom_up = dict(), dict()\n",
    "    grouped_by_pdb = df.groupby('pdb_id')\n",
    "\n",
    "    # For each PDB...\n",
    "    for pdb_id, pdb_group in grouped_by_pdb:\n",
    "        unique_levels = sorted(pdb_group['level'].unique())\n",
    "\n",
    "        # For each hierarchy level in the autoencoder...\n",
    "        for level in unique_levels:\n",
    "            lower_level, upper_level = level, level + 1  \n",
    "            lower_level_group = pdb_group[pdb_group['level'] == lower_level].sort_values(by='level_idx')\n",
    "            upper_level_group = pdb_group[pdb_group['level'] == upper_level].sort_values(by='level_idx')\n",
    "            num_lower_level = len(lower_level_group)\n",
    "            for start in range(0, num_lower_level, stride):\n",
    "                end = start + kernel_size\n",
    "                lower_level_slice = lower_level_group.iloc[start:end]\n",
    "                upper_level_node_index = start // stride\n",
    "                # upper_level_node_index = start \n",
    "                if upper_level_node_index < len(upper_level_group):\n",
    "                    upper_level_node = upper_level_group.iloc[upper_level_node_index]\n",
    "\n",
    "                    # Key is pk of upper node, value is list of pks for all lower nodes\n",
    "                    edges_top_down[upper_level_node.name] = list(lower_level_slice.index)\n",
    "\n",
    "                    # Key is the index of the lower node, value is the index of upper node\n",
    "                    edges_bottom_up.update(dict.fromkeys(lower_level_slice.index, upper_level_node.name))\n",
    "                else:\n",
    "                    n_misses += 1\n",
    "\n",
    "        # print(f\"Processed PDBid: {pdb_id}\")\n",
    "\n",
    "    return edges_top_down, edges_bottom_up, n_misses\n",
    "\n",
    "edges_top_down, edges_bottom_up, n_misses = connect_edges(df_small, kernel_size, stride)\n",
    "print(f\"Missed: {n_misses} edges\")\n",
    "whatis(edges_top_down, edges_bottom_up)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f24abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_top_down, edges_bottom_up, n_misses = connect_edges(df_small, kernel_size, stride)\n",
    "print(f\"Missed: {n_misses} edges\")\n",
    "correct_edges = edges_bottom_up.copy()\n",
    "whatis(correct_edges)\n",
    "whatis(edges_top_down, edges_bottom_up)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c377983c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_edges = edges_bottom_up.copy()\n",
    "whatis(wrong_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89083492",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Convert the edges_bottom_up dictionary to a list of tuples with integers\n",
    "edges_bottom_up_tuples = [(int(k), int(v)) for k, v in correct_edges.items()]\n",
    "\n",
    "# Convert the list of tuples to JSON format\n",
    "edges_bottom_up_json = json.dumps(edges_bottom_up_tuples)\n",
    "\n",
    "# Save the JSON data to a file\n",
    "with open('correct_edges.json', 'w') as file:\n",
    "    file.write(edges_bottom_up_json)\n",
    "\n",
    "print(\"edges_bottom_up has been saved to edges_bottom_up.json\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82464ec",
   "metadata": {},
   "source": [
    "### Plot with Sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddce14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small['color'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e19b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64efec23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_small.drop(columns=['datum']).to_json('df_small_export_nodatum.json', orient='records')\n",
    "\n",
    "\n",
    "# df_small.to_json('df_small_export.json', orient='records')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfce28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertical_shift = 250\n",
    "layout = {\n",
    "    idx: {\n",
    "        \"x\": float(row['pos'][0]),\n",
    "        \"y\": float(row['pos'][1]) + vertical_shift * row['level'],\n",
    "\n",
    "    } for idx, row in df_small.iterrows()\n",
    "}\n",
    "\n",
    "graph = nx.Graph()\n",
    "for idx, row in df_small.iterrows():\n",
    "    graph.add_node(idx, level=row['level'], level_idx=row['level_idx'])\n",
    "\n",
    "# graph.add_nodes_from(df_small.index)\n",
    "# graph.add_edges_from(edges_bottom_up.items())\n",
    "\n",
    "graph.add_edges_from(correct_edges.items())\n",
    "# graph.add_edges_from(wrong_edges.items())\n",
    "\n",
    "print(f\"There are {graph.number_of_nodes()} nodes in the graph\")\n",
    "\n",
    "edge_kwargs = dict(\n",
    "    default_edge_type=\"curve\",\n",
    "    default_edge_curveness=0.2,\n",
    "    default_edge_size=1.0,\n",
    "    clickable_edges=True\n",
    ")\n",
    "\n",
    "node_kwargs = dict(\n",
    "    node_label={idx: row['pdb_id'] for idx, row in df_small.iterrows()},\n",
    "    raw_node_color=df_small['color'].values,\n",
    "    node_border_color_from='node',\n",
    ")\n",
    "\n",
    "sigma = Sigma(\n",
    "    graph,\n",
    "    layout=layout,\n",
    "    node_metrics=['louvain'],\n",
    "    # node_metrics={\"community\": {\"name\": 'louvain', \"resolution\": 0.5}},\n",
    "    # node_color='louvain',\n",
    "    **node_kwargs,\n",
    "    **edge_kwargs\n",
    ")\n",
    "sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f3d188",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_bottom_up[1342]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f66bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839eacc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma.get_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
